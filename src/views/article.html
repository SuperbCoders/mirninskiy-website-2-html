			@@include('../blocks/modules/head/head.html', {
				"title": "«Он может попасть не в те руки, как и обычное оружие» | Мирнинский рабочий" 
			})

			<div id="site">
				@@include('../blocks/modules/header/header.html')

				<!-- section BEGIN -->
				<section class="section section--theme_light">
					<div class="container section__container">
						<article class="article-page">
							<div class="content">
								<time datetime="2020-09-30 00:04">00:04, 30 сентября 2020</time>
								<h1>«Он может попасть не в те руки, как и обычное оружие»</h1>
								<p>Искусственный интеллект уже помогает людям, но законы его не контролируют. Чем это опасно?</p>
								<figure>
									<picture>
										<source srcset="images/article-page-1.webp" type="image/webp">
										<img src="images/article-page-1.jpg" alt="Искусственный интеллект уже помогает людям, но законы его не контролируют. Чем это опасно?">
									</picture>
									<figcaption>Фото: Athit Perawongmetha / Reuters</figcaption>
								</figure>
								<p>В 2020 году многим стало очевидно, что грань между реальностью и виртуальностью практически перестала существовать: это показал карантин, во время которого миллионы людей жили полноценной жизнью, практически не выходя из дома. Однако исследователи уже убедились, что технологии несут не только благо. Оказавшись в неправильных руках, они могут превратиться в полную противоположность того, для чего они были задуманы. Как избежать угроз, которые несет развитие технологий, — в материале «Мирнинскийрабочий.ру».</p>
								<h2>«Постбиотическая жизнь»</h2>
								<p>«Рассуждая об искусственном интеллекте и искусственном сознании, многие полагают, что существует всего два класса систем обработки информации: искусственные и естественные. Это не так», — писал немецкий философ Томас Метцингер. В пример систем, которые не принадлежат ни к одной из этих категорий, он приводил гибридных биороботов или разработку британских ученых из Редингского университета: они научились управлять роботом, используя сеть из трехсот тысяч крысиных нервных клеток. Такие системы Метцингер предлагает называть постбиотической жизнью.</p>
								<figure>
									<blockquote cite="http://www.w3.org/html/wg/drafts/html/master/grouping-content.html#the-figure-element">Пока мы не стали существенно счастливее, чем были наши предки, лучше не пытаться перенести нашу психическую структуру на искусственные носители</blockquote>
								  	<figcaption>Томас Метцингер</figcaption>
								</figure>
								<p>Философ, однако, сомневается в том, что человеку удастся «пересоздать» себя на небиологическом носителе. Искусственное сознание — это в первую очередь техническая проблема, и никто не может гарантировать, что ее удастся решить. С другой стороны, это проблема этическая. «Пока мы не стали существенно счастливее, чем были наши предки, лучше не пытаться перенести нашу психическую структуру на искусственные носители», — предостерегал Метцингер.</p>
								<p>Услышав словосочетание «искусственный интеллект», многие представляют разумных человекоподобных роботов и прочую постбиотическую жизнь, способную осознавать себя. На самом же деле искусственный интеллект — это система, которая способна анализировать данные и обучаться на их основе.</p>
								<p>Искусственный интеллект действительно способен выполнять те задачи, которые раньше были доступны только людям, — например, давать рекомендации, какой сериал посмотреть, переводить тексты или играть в шахматы.</p>
								<figure>
									<picture>
										<source srcset="images/article-2.webp" type="image/webp">
										<img src="images/article-2.jpg" alt="Искусственный интеллект уже помогает людям, но законы его не контролируют. Чем это опасно?">
									</picture>
									<figcaption>Фото: Mohamed Abd El Ghany / Reuters</figcaption>
								</figure>
								<p>Технология — это не замена человека, а его помощник, призванный делать жизнь лучше. Например, искусственный интеллект активно используют в медицине: исследователи создают нейросети, способные предсказывать серьезные заболевания, прогнозировать риски и искать новые лекарства. ИИ также применяют при диагностике, однако опасаться, что машина будет неправильно лечить человека, не стоит: решения принимает врач, а не компьютер. При создании таких технологий много внимания уделяется этическому аспекту. При проектировании ученые всегда ориентируются на то, что технологии существуют для людей, а не наоборот.</p>
								<p>Не менее важным для будущего искусственного интеллекта является правовой аспект. Принципы, которым должны следовать ученые при развитии этой технологии, были сформулированы в 2017 году на конференции в американском городе Азиломар. Под ними подписались более 3,5 тысячи ученых, в том числе Стивен Хокинг. Свои подписи поставили и представители Google, Apple, Facebook, IBM, Microsoft и Илон Маск. Первым азиломарским принципом стало то, что цель исследований в области интеллектуальных систем должна заключаться в создании не «бесцельного разума», а систем, способных принести человеку пользу.</p>
								<div class="content__similar-article">
									<div class="rubric">Похожие новости</div>
									<article class="article article--theme_simple section__article">
										<header class="article__header">
											<h2 class="article__title">
												<a href="#" class="link-cover article__link">65 лет трубкам «Мир» и «Удачная»</a>
											</h2>
										</header>
										<p class="article__description">Давно выяснено, что при оценке дизайна и композиции читаемый текст мешает сосре...</p>
									</article>
									<article class="article article--theme_simple section__article">
										<header class="article__header">
											<h2 class="article__title">
												<a href="#" class="link-cover article__link">65 лет трубкам «Мир» и «Удачная»</a>
											</h2>
										</header>
										<p class="article__description">Давно выяснено, что при оценке дизайна и композиции читаемый текст мешает сосре...</p>
									</article>
								</div>
								<p>Исследователи также согласились с тем, что между разработчиками искусственного интеллекта и правительством необходим диалог. Как модифицировать правовую систему, чтобы учесть все правовые риски, связанные с использованием интеллектуальных систем — этот вопрос пока остался открытым. Однако то, что он поднимался, говорит о назревшей необходимости менять законодательства разных стран с учетом того, как технологии изменили и продолжают менять мир.</p>
								<p>Особенно очевидно это стало во время пандемии коронавируса, когда многие страны ввели строгие карантинные меры. Огромное количество людей стало работать и учиться прямо из дома — можно сказать, что грань между реальностью и виртуальностью стерлась окончательно. Тогда же стало ясно, что нормы закона и этики не могут быть разными для онлайна и офлайна — разделить невозможно.</p>
								<h2>Страх перед искусственным интеллектом</h2>
								<p>О технологии искусственного интеллекта знают около 75 процентов россиян, однако лишь 29 процентов из них понимают ее суть — об этом свидетельствуют данные опроса ВЦИОМ, проведенного в конце 2019 года.</p>
								<p>Большинство респондентов отметили, что относятся к внедрению этой технологии положительно или нейтрально. Более половины участников исследований согласились использовать ИИ для получения госуслуг, для решения различных бытовых задач, а также в медицине, образовании и сфере досуга.</p>
								<div class="content__percent">
									<div class="content__percent-count"><span>12</span>процентов</div>
									<p class="content__percent-text">негативно относятся к внедрению технологий искусственного интеллекта</p>
								</div>
								<p>Негативно к распространению искусственного интеллекта относится 12 процентов опрошенных. Директор по работе с органами государственной власти ВЦИОМ Кирилл Родин подчеркнул, что с каждым годом их число снижается.</p>
								<p>Страх перед ИИ обусловлен опасениями, связанными с утечкой персональных данных, нарушением личного пространства и техническими сбоями. Кроме того, участников опроса заботило то, что предсказать последствия развития технологий пока невозможно.</p>
								<p>«С одной стороны — признают неизбежность и необходимость развития искусственного интеллекта как обеспечивающего стратегическое преимущество в технологической революции. С другой — читается настороженность, во многом продиктованная непониманием, как конкретно внедрение технологии повлияет на повседневную жизнь», — прокомментировал результаты опроса Родин.</p>
								<h2>Технологии во благо</h2>
								<p>Об этих же опасностях говорил президент России Владимир Путин, выступая на пленарном заседании 75-й сессии Генеральной ассамблеи ООН. Путин отметил, что пандемия коронавируса стала принципиально новым вызовом, и экспертам еще предстоит оценить масштабы ее последствий. В то же время пандемия «заострила и целый ряд этических, технологических, гуманитарных тем».</p>
								<figure>
									<blockquote cite="http://www.w3.org/html/wg/drafts/html/master/grouping-content.html#the-figure-element">Мы должны учиться использовать новые технологии во благо человечеству, найти правильный баланс между стимулами к развитию искусственного интеллекта и оправданными ограничительными мерами, совместными усилиями прийти к согласию в сфере регулирования, которое исключило бы потенциальные угрозы, причем с точки зрения не только военной, технологической безопасности, но и традиций, права, морали человеческого общения</blockquote>
								  	<figcaption>Владимир Путин</figcaption>
								</figure>
								<p>В частности, президент подчеркнул, что технологии помогли перестроить систему образования и другие сферы, а также перевести уроки в онлайн. Кроме того, искусственный интеллект часто помогал врачам ставить диагноз и подбирать схему лечения. «Но, как и любые другие инновации, цифровые технологии имеют тенденцию к неуправляемому распространению и так же, как и обычное оружие, могут попасть в руки разного рода радикалов и экстремистов не только в зонах региональных конфликтов, но и во вполне благополучных странах, порождая огромные риски», — отметил Путин.</p>
								<p>По его мнению, многие люди опасаются, что технологии поставят под угрозу базовые человеческие права: право на частную жизнь, собственность и безопасность. «Мы должны учиться использовать новые технологии во благо человечеству, найти правильный баланс между стимулами к развитию искусственного интеллекта и оправданными ограничительными мерами, совместными усилиями прийти к согласию в сфере регулирования, которое исключило бы потенциальные угрозы, причем с точки зрения не только военной, технологической безопасности, но и традиций, права, морали человеческого общения», — констатировал президент России.</p>
								<figure class="img-left">
									<picture>
										<source srcset="images/article-page-3.webp" type="image/webp">
										<img src="images/article-page-3.jpg" alt="Ирина Рукавишникова">
									</picture>
									<figcaption>Ирина Рукавишникова</figcaption>
								</figure>
								<p>Первый заместитель председателя комитета Совета Федерации по конституционному законодательству и государственному строительству, член Совета по развитию цифровой экономики при Совете Федерации Ирина Рукавишникова отметила, что угрозы, исходящие от цифрового мира, разнообразны по формам, адресатам и степени опасности. «Одни злоумышленники с помощью вирусов, фальшивых подписных страниц или сайтов и многих других методов стремятся завладеть персональными данными граждан для хищения их денежных средств. Другие — более изощренные — стремятся дестабилизировать работу предприятий и организаций, отраслей и систем жизнеобеспечения, массово ввести население в заблуждение и посеять панику с помощью фейковых новостей», — уточнила Рукавишникова в разговоре с «Мирнинскийрабочий.ру».</p>
								<p>По ее мнению, противостоять этому можно как минимум на четырех уровнях. «Первый — законодательство. Оно должно оперативно реагировать на все новые возможности и риски, которые несет с собою цифровое пространство. Второй — поддержка и совершенствование отечественных конкурентоспособных продуктов в сферах программного обеспечения, систем сбора, обработки, передачи и хранения данных», — объяснила член Совфеда.</p>
								<p>Рукавишникова подчеркнула важность подготовки достаточного количества специалистов по вопросам кибербезопасности, включая узкоотраслевых профессионалов, специализирующихся, к примеру, на медицине или строительстве. Уже сегодня их недостаточно, а в будущем потребность будет только расти. Кроме того, она обратила внимание на повышение уровня цифровой грамотности граждан: «Ведь любое, даже самое совершенное законодательство будет бессильно перед киберугрозами, если пользователи сети будут пренебрегать элементарными требованиями безопасности».</p>
								<div class="article-slider content__slider">
									<div class="js-article-slider-init article-slider__block">
										<div class="content article-slider__slide">						
											<figure>
												<picture>
													<source srcset="images/article-page-2.webp" type="image/webp">
													<img src="images/article-page-2.jpg" alt="Фото: Paul Hanna / Reuters">
												</picture>
												<figcaption>Фото: Paul Hanna / Reuters</figcaption>
											</figure>
										</div>
										<div class="content article-slider__slide">						
											<figure>
												<picture>
													<source srcset="images/article-page-2.webp" type="image/webp">
													<img src="images/article-page-2.jpg" alt="Фото: Paul Hanna / Reuters">
												</picture>
												<figcaption>Фото: Paul Hanna / Reuters</figcaption>
											</figure>
										</div>
									</div>
									<div class="js-article-pagination article-slider__pagination">null из null</div>
								</div>
								<p>«Далеко не все наши соотечественники внимательно следят за тем, что именно, какие сведения и куда они передают, какие согласия подписывают на автомате, к чему это может привести. Любое право, включая возможность бесплатного пользования социальными сетями, видеохостингами, поисковыми системами и так далее, налагает на гражданина и определенные обязанности, в том числе по обеспечению безопасности информации, которую человек сознательно размещает, например, в социальных сетях. Об этом россияне, к сожалению, часто забывают», — констатировала Рукавишникова.</p>
								<p>О важности учитывать этические вопросы при создании искусственного интеллекта говорят и эксперты индустрии. По словам советника по стратегии и развитию в Common Fund for Commodities Андрея Кулешова, технология, не соответствующая этическим критериям, принятым в обществе, вероятно, столкнется с долгим и проблемным процессом внедрения, невзирая на любой позитивный потенциал. С этой точки зрения открытое и прозрачное соблюдение этических принципов всеми участниками производства и внедрения систем ИИ может здорово упростить процесс принятия технологий обществом.</p>
								<figure class="img-left">
									<picture>
										<source srcset="images/article-page-4.webp" type="image/webp">
										<img src="images/article-page-4.jpg" alt="Ирина Рукавишникова">
									</picture>
									<figcaption>Ирина Рукавишникова</figcaption>
								</figure>
								<p>«С другой стороны, инновационные технологии, такие как ИИ, часто вынуждены работать в "серой" зоне неясной ответственности за непредвиденные негативные последствия. ИИ как масштабируемая технология может столкнуться не только с неопределенной ответственностью, но и с неопределенным ее масштабом, что, конечно, не способствует уверенности при внедрении инноваций», — подчеркнул Кулешов и добавил, что соблюдение вопросов этики, по сути, необходимо как условие рационального, взаимоприемлемого баланса между интересами корпораций, ученых, разработчиков, общества, человека, государства.</p>
								<p>Изучением того, как можно снизить существующие риски, сегодня занимаются и в Международной организации по стандартизации, в ЮНЕСКО, Совете Европы и ОБСЕ.</p>
								<p>Общими подходами для разработчиков Кулешов назвал принципы предосторожности, информированного согласия и ненаделения искусственного интеллекта собственной субъектностью. «Этику должна соблюдать не система (железка не имеет своей этики), а люди, которые за ней стоят», — уточнил специалист. По его словам, кодифицировать общие принципы помогает опыт других профессий с этической нагрузкой — например, медицины и финансов. Он подсказывает, что ИИ должен действовать в интересах развития общества, соблюдать закон, интересы общества и граждан, действовать ответственно и добросовестно, проявлять профессионализм и компетентность, а также укреплять доверие к технологиям и рынкам.</p>
							</div>
							<div class="article-page__author">
								<a href="#">Антон Герасимов</a>
							</div>
							<div class="tag-list article-page__tags">
								<a href="#" class="tag tag-list__item">Экономика и бизнес</a>
								<a href="#" class="tag tag-list__item">Технология</a>
								<a href="#" class="tag tag-list__item">Boston dynamics</a>
							</div>
						</article>
					</div>
				</section>
				<!-- section END -->

				@@include('../blocks/modules/footer/footer.html')
			</div>

			<script src="js/main.js"></script>
			<script src="js/vendor.js"></script>
	</body>
</html>